{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reimplementation of Image Super-Resolution Using Deep Convolutional Network in PyTorch\n",
    "\n",
    "This notebook is the reimplementation of this [paper](https://arxiv.org/abs/1501.00092)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        self.file = h5py.File(file_path, 'r')\n",
    "        self.data = self.file['data']\n",
    "        self.label = self.file['label']\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        image = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.label[idx], dtype=torch.float32)\n",
    "        \n",
    "        return image, label\n",
    "    \n",
    "    def close(self):\n",
    "        self.file.close()       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Datasets and Dataloaders\n",
    "\n",
    "The train.h5 and test_set.h5 files are obtained by running the MATLAB scripts generate_train and generate_test respectively from [this](https://mmlab.ie.cuhk.edu.hk/projects/SRCNN/SRCNN_train.zip) source code given in the original paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset and dataloader\n",
    "dataset = MyDataset('train.h5') \n",
    "train_loader = DataLoader(dataset, batch_size=128)\n",
    "\n",
    "dataset_test_set5 = MyDataset('test.h5')\n",
    "val_loader = DataLoader(dataset_test_set5, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SRCNN model\n",
    "class SRCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=9, stride=1, padding=0)  # Changed input channels to 1\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=1, stride=1, padding=0)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.conv3 = nn.Conv2d(32, 1, kernel_size=5, stride=1, padding=0)  # Changed output channels to 1\n",
    "        \n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu1(self.conv1(x))\n",
    "        out = self.relu2(self.conv2(out))\n",
    "        out = self.conv3(out)\n",
    "        # Resize output to match labels dimensions (21, 21)\n",
    "        #out = F.interpolate(out, size=(21, 21), mode='bicubic', antialias=False)\n",
    "        return out\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        # Initialize weights with Gaussian distribution (std=0.001) and bias with zeros\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # Initialize convolutional layer weights with Gaussian distribution (std=0.001)\n",
    "                nn.init.normal_(m.weight, mean=0, std=0.001)\n",
    "                if m.bias is not None:\n",
    "                    # Initialize bias with zeros\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "model = SRCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define different learning rates and multipliers for weights and biases\n",
    "learning_rates = {\n",
    "    'conv1_weight': 1e-4 * 1.0,\n",
    "    'conv1_bias': 1e-4  * 0.1,\n",
    "    'conv2_weight': 1e-4 * 1.0,\n",
    "    'conv2_bias': 1e-4 * 0.1,\n",
    "    'conv3_weight': 1e-5 * 0.1,\n",
    "    'conv3_bias': 1e-5 * 0.1 \n",
    "}\n",
    "\n",
    "# Group parameters and assign specific learning rates with multipliers\n",
    "param_groups = []\n",
    "for name, param in model.named_parameters():\n",
    "    if name in learning_rates:\n",
    "        lr = learning_rates[name]\n",
    "    else:\n",
    "        lr = 0.0001  # Default learning rate for other parameters\n",
    "\n",
    "    param_groups.append({'params': param, 'lr': lr})\n",
    "\n",
    "optimizer = optim.SGD(param_groups, lr=0.0001, momentum=0.9, weight_decay=1e-4)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.19692319421207202\n",
      "Epoch 2, Loss: 0.11591762593563865\n",
      "Epoch 3, Loss: 0.07518237704301582\n",
      "Epoch 4, Loss: 0.05482223765815006\n",
      "Epoch 5, Loss: 0.04464743910905193\n",
      "Epoch 6, Loss: 0.03956396030809949\n",
      "Epoch 7, Loss: 0.03702495014842819\n",
      "Epoch 8, Loss: 0.035757218180772134\n",
      "Epoch 9, Loss: 0.03512446486993748\n",
      "Epoch 10, Loss: 0.034808737751753895\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        # Print shapes of outputs and labels\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print average loss after each epoch\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "# Save the trained model\n",
    "torch.save(model.state_dict(), 'srcnn_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.05704200948140895\n"
     ]
    }
   ],
   "source": [
    "#Evaluate model on validation dataset\n",
    "model.eval()\n",
    "val_loss = 0.0\n",
    "for batch_idx, (val_inputs, val_labels) in enumerate(val_loader):\n",
    "    val_outputs = model(val_inputs)\n",
    "    val_loss += criterion(val_outputs, val_labels).item()\n",
    "\n",
    "average_val_loss = val_loss / len(val_loader)\n",
    "print(f\"Validation Loss: {average_val_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating PSNR values for validation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate PSNR between two images\n",
    "def calculate_psnr(img1, img2):\n",
    "    mse = np.mean((img1 - img2) ** 2)\n",
    "    if mse == 0:\n",
    "        return float('inf')  # PSNR is infinite if images are identical\n",
    "    MAX = 255.0\n",
    "    psnr = 10 * np.log10((MAX**2) / mse)\n",
    "    return psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average PSNR: 62.23 dB\n"
     ]
    }
   ],
   "source": [
    "psnr_values = []\n",
    "\n",
    "for inputs, labels in val_loader:\n",
    "    # Move inputs and labels to the device\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Generate predictions using the model\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs)\n",
    "    \n",
    "    outputs = outputs.cpu().detach().numpy()\n",
    "    labels = labels.cpu().detach().numpy()\n",
    "    \n",
    "    # Calculate PSNR for each image pair\n",
    "    for i in range(outputs.shape[0]):  # Iterate over batch size\n",
    "        psnr_value = calculate_psnr(outputs[i].squeeze(), labels[i].squeeze())\n",
    "        psnr_values.append(psnr_value)\n",
    "\n",
    "# Compute average PSNR over all images in the dataset\n",
    "average_psnr = np.mean(psnr_values)\n",
    "print(f\"Average PSNR: {average_psnr:.2f} dB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
